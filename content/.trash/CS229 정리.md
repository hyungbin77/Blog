# Lecture 4 - Perceptron & GLM


## Perceptron
- sigmod function은  무한대에서 무한대까지의 값을 0과 1사이에 압축 
- 여러 데이터 항목의 입력을 받아서 출력은 이진으로 0또는 1을 출력하는 분류 알고리즘 
![[Pasted image 20241112181556.png|400]]
- 가중치 $\theta$ 를 찾기위한 업데이트 방법(Gradient Descent)

- 데이터가 2개 feature를 가질때  다음 점선이 분류 모델의 기준 선 

![[Pasted image 20241112182245.png|400]]


- 목표 : $\theta$ 에 수직인 decision boundary가 모든 positive x를 한 쪽에 오도록 하는 $\theta$ 를 구하는 것 
- x를 잘 분류 했다면 $\theta$ 를 수정하지 않고 잘못 분류 했다면 x가 positive한 경우 x와 가까워지도록 ,
  negative인 경우 x와 멀어지도록 $\alpha x$를 더하고 빼서 $\theta$를 회전시킴 





<div style="page-break-after: always;"></div>

## Exponential Family 

![[Pasted image 20241112183039.png|350]]
- 지수함수와 연관되어 있는 특정 확률분포 종류 
- y의 분포 유형에 따라서 적절한 추가 함수를 만들어 모델을 적용할 수 있음 
### properties
- Maximum Likelihood 가 concave하다
	- Negative Log Liklihoode 가 convex하다
- $E[y;\eta] = \frac{d}{d\eta}a(\eta)$ 
- $Var(y;\eta) = \frac{d^{2}}{d\eta^{2}}a(\eta)$

![[Pasted image 20241112184750.png|350]]


<div style="page-break-after: always;"></div>




![[Pasted image 20241112184806.png|350]]
- 이러한 지수함수 계열은 데이터의 유형에 따라 선택하여 모델에 적용가능
	Real - Gaussian
	Binary - Bernoulli
	Count - Poisson
	R - Gamma, Exponential
	Distn - Beta , Dirichlet
	
## Generalized Linear Model 

-  Assumptions / Design Choices
	(i)  $y|x;\theta$  ~ Exponential Family($\eta$)
	(ii) $\eta = \theta^{T}x \quad \theta \; in\; \mathbb{R}^{n}, \; x\in \mathbb{R}^{n}$ 
	(iii) Test time  : Output $E[y|x;\theta]$    
![[Pasted image 20241112185646.png|500]]
- 이는 GLM의 전체적인 과정을 도식화 
- $\eta$ 는 선형모델의 훈련을 통해 나온 결과 값 , 훈련 시 입력된 데이터 X 



- GLM에 다른 확률분포를 사용하더라고 Learning update rule은 항상 같다
$$\theta_{j} := \theta_{j} + \alpha(\Sigma y^{(i)} - h_{\theta}(x^{(i)}))x_{j}^{(i)}$$
- $\eta$ : natural parameter
- $\mu = E(y;\eta) = g(\eta)$ : canonical Response function
- $\eta = g^{-1}(\mu)$ : canonical link function 
	- $g(\eta) = \frac{d}{d\eta}g(\eta)$

<div style="page-break-after: always;"></div>
### 3 - parametrizations
*GLM은 3가지 방법으로 parameterization(매개변수화)할 수 있다*
- Model parameter : $\theta$
- Natural parameter : $\eta$
- Canonical parameter : ($\phi$ - bernoulli), ($\mu, \sigma^{2}$ -gaussian),($\lambda$ - poisson)
-> 어떤 분포를 고를지 = 어떤 data, task를 진행할건지 

-  GLM에서 학습을 할 때 model parameter $\theta$ 만을 학습을 한다. 
- model parameter 와 natural parameter 는 선형적으로 연결되어있다
- $\theta^{T}x$를 통해 natural parameter $\eta$를 구할 수 있고 이것이 우리가 만든 design choice
- natural parameter 와 canonical parameter 는 $g$ 와 $g^{-1}$ 를  통해 연결되어 있다
- 우리가 학습시킨 모델의 parameter와 이것의 output인 exponential family의 natural parameter, 그리고 수식을 정리하여 얻을 수 있는 우리가 목적에 맞게 고른 확률분포의 canonical parameter를 통해 GLM을 parameterization할 수 있다

###  Softmax Regression
- Softmax regression은 GLM family의 한 종류로 설명할 수 있다.
- Cross-entropy로 더욱 간결히 표현이 가능하고 최종적으로 GLM의 표현과 같아진다 
- K - # classes
- $x^{(i)} \in \mathbb{R}^{n}$
- Label y = $[\{0,1\}^{k}]$
- $\theta_{class} \in \mathbb{R}^{n}$
 - softmax regression에선 각 클래스마다 $\theta$거 존재하므로 클래스 별로 decision boundary가 존재 
 ![[Pasted image 20241112220458.png|400]]

<div style="page-break-after: always;"></div>
새로운 데이터가 들어왔다면?
- 각 클래스별로 시그모이드 함수의 값에 exp값을 취한다 
- 정규화

- softmax regression의 목적은 예측한 확률분포와 실제 확률분포 사이의 거리를 최소화 
- 두 분포 사이의 cross entropy를 최소화하는 방법으로 학습할 수 있다 
$$cross Entropy(p,\hat{p}) = -\Sigma_{y\in class}p(x)log\hat{p(y)}$$

<div style="page-break-after: always;"></div>



# Lecture 7 - Kernel 

## Optimization Problem

$$\min_{w,b}\frac{1}{2}||w||^{2}$$
$$s.t \quad y^{(i)}(w^{T}x^{(i)} + b) \geq 1$$
- geometric margin을 최대화하면서 w,b로 parameterized 되어 있는 decision boundary를 찾아야한다
$$\gamma^{(i)} = \frac{y^{i}(w^{T}x^{(i)} + b)}{||w||}$$
$$\gamma = \min_{i}\gamma^{(i)}$$
for optimization problem
$$\max_{\gamma,w,b} \gamma$$
$$s.t \quad \frac{y^{(i)}(w^{T}x^{(i)}+ b)}{||w||} \geq \gamma , \quad i = 1,...,m$$
- 위의 식을 간단하게 하기 위해 $||w|| = \frac{1}{\gamma}$ 가 되도록 상수를 곱해주면 아래 식이 나옴
$$\max_{w,b} \frac{1}{||w||}$$
$$s.t. \quad. y^{(i)}(w^{T}x^{(i)} + b) \geq 1, \quad i = 1,...,m$$
이를  $||w||^{2}$ 를 최소화하는 식으로 변환하면 
$$\min_{w,b}||w||^{2}$$
$$s.t. \quad y^{i}(w^{T}x^{(i)} + b) \geq 1, \quad, i = 1,...,m$$



## Kernel Trick 

1) Write algorithm in terms of <x,z>
2) feature x의 숫자에 상관없이 mapping을 통해 많은 feature를 만들 수 있다 
$$x -> \Phi(x)$$
3)  Find way to compute K(x,z) = $\Phi(x)^{T}\Phi(Z)$
	- K = kernel function  
4) Replace <x,z> in algorithm with K(x,z)

#### example 
$$x = [x_{1},x_{2},x_{3}]$$
$$x \in \mathbb{R}^{n}$$- 이라하면, 아래와 같이 x를 고차원으로 매핑시킨 $\Phi(x)$를 만들 수 있다 
$$\Phi(x) = 

\begin{bmatrix}

x_{1}x_{1} \\

x_{1}x_{2} \\
x_{1}x_{3}  \\
x_{2}x_{1}  \\
x_{2}x_{2}  \\
x_{2}x_{3} \\
x_{3}x_{1}  \\
x_{3}x_{2}   \\
x_{3}x_{3}

\end{bmatrix}


$$
$$\Phi(z) = 

\begin{bmatrix}

z_{1}z_{1} \\

z_{1}z_{2} \\
z_{1}z_{3}  \\
z_{2}z_{1}  \\
z_{2}z_{2}  \\
z_{2}z_{3} \\
z_{3}z_{1}  \\
z_{3}z_{2}   \\
z_{3}z_{3}

\end{bmatrix}

$$
$$\Phi(x) \in \mathbb{R}^{n^{2}}$$
$\Phi(x) \in \mathbb{R}^{n^{2}}$ 로 정의했기 때문에 3개의 변수가 9개의 변수로 변경, 이를 계산하기 위해서는 O($n^{2}$)
계산 복잡도가 필요 

$$K(x,z) = \Phi(x)^{T}\Phi(z) = (x^{T}z)^{2}$$
$$ = (\Sigma_{i = 1}^{n}x_{i}z_{i})(\Sigma_{j=1}^{n}x_{j}z_{j})$$
$$ = \Sigma_{i = 1}^{n}\Sigma_{j=1}^{n}(x_{i}x_{j})(z_{i}z_{j})$$
- 이전에 함수 형태일때는 둘의 곱으로 $O(n^{2})$   의 시간 복잡도를 가짐 
- x,z는 n차원이기 때문에 $O(n)$ 로 시간 복잡도가 내려감 

- SVM = Optimal margin classifier + Kernel Trick = Support Vector machine 
- 적은 데이터로 많은 feature들을 만들어서 효율적으로 계산하여  효과적으로 분류하는 모델을 
  만듬 

*How to make kernels*
$$K(x,z) = exp(-\frac{||x-z||^{2}}{2\sigma^{2}})$$
- x,z가 비슷하다면 K(x,z) (내적)이 큼 , 매우가까우면 1 

- $K(x,z) = \phi(x)^{T}\phi(z)$ 를 만족하는 $\phi$ 가 존재할때에만 kernel function으로 사용할 수 있다. 
- 자기 자신과의 내적은 음수가 될 수 없으므로 K(x,x) 가 0보다 작으면 유요한 kernel function dl dkslek 

*Soft Margin SVM*
- data 가 noisy하게 섞여 있을 경우 완벽하게 분리하려고 하면 decision boundary가 매우 복잡해진다
- 고차원의 feature spcae에서도 linear하게 분리되지 않는 경우 training set 에 대해 error가 0인 알고리즘을 원하지 않을 수 있다
- 이런 algorithm을 L1 norm soft margin SVM이라고 한다 
$$min_{w,b,\xi} \frac{1}{2}||w||^{2} + C\Sigma_{i=1}^{m}\xi_{i}$$
$$s.t \quad y^{i}(w^{T}x^{(i) }+ b) \geq 1- \xi_{i}, \quad \xi_{i} \geq 0$$

- functional margin이 0보다 크다면 algorithm이 문제를 알맞게 분류했다는 의미
- SVM은 알맞게 분류한 것 뿐만 아니라 1보다 큰 functional margin과 함께 알맞게 분류해야함 
<div style="page-break-after: always;"></div>

# Lecture 13 - Debugging ML Models and Error Analysis

- Debugging learning algorithm
- 머신 러닝에서 어떤 알고리즘을 실행한다고 항상 제대로 작동하는건 아님 
- 제대로 작동 하지 않으면 그 다음 무엇을 해야할지 고민 
- 그에따른 디버깅 전략이 필요 

### Motivating example
- Anti-spam. You carefully choose a small set of 100 words to use as features
  (Instead of using all 50000+ words in English)
- Logistic regression with regularization (Bayesian Logistic regression), implemented with gradient ascent, gets 20%. test error , which is unacceptably high
$$Max_{\theta}\Sigma_{i=1}^{m}logp(y^{i}|x^{i},\theta) - \lambda||\theta||^{2}$$
- what to do next? 

*Common approach*
> Try getting more training examples.         Fixes high variance
> Try a smaller set of features.                     Fixes high variance
> Try a larger set of features                        Fixes high bias
> Try changing the features : Email header vs email body features  Fixes high bias
> Run gradient descent for more iterations.            Fixes optimizaiton algorithm
> Try Newton's method                                              Fixes optimizaiton algorithm
> Use a different value for $\lambda$                                      Fixes optimizaiton objective
> Try using an SVM


- 프로젝트 경험 등등 주관에 의해 결정된다 

- 제가 학습 알고리즘을 개발할때 가장 먼저 하는건 편향 대 분산 진단 

## Diagnostic for bias VS variance

Better approach :
	- Run diagnostics to figure out what the problem is
	- Fix whatever the problem is 

Logistic regression's test error is 20% (unacceotably high)

Suppose you suspect the problem is either :
	- Overfitting (high variance)
	- Too few features to classify spam (high bias)

Diagnostic :
	- Variance : Training error will be much lower than test error.
	- Bias : Training error will also be high 




Typical learning curve for high variance:
![[스크린샷 2024-11-12 오후 4.05.38.png|350]]
- Test error still decreasing as m increases. Suggests larger training set will help
- Large gap between. training and test error 
- 이 그림은 variance problem의 강력한 신호 


Typical learning curve of high bias:
![[Pasted image 20241112161139.png|350]]
- Even training error is unacceptably high
- Small gap between training and test error 
- 데이터를 많이 얻는다고 좋아지지 않음 
- high bias의 문제는 이 알고리즘이 훈련 세트에서 제대로 작동하지 않는다 


어떤 문제를 직면할지 모른다 ,  일단 로지스틱을 돌리고 문제점 파악 -> 더 좋은 알고리즘 or 데이터 추가/개선


## Optimization algorithm ddiagnostics

- Bias vs variance is one common diagnostic

- For other problems, it's usually up to your own ingenuity yo construct your own diagnostics to figure out what's wrong

- Another example :
	- Logistic regression gets 2% error on spam, and 2% error on non-spam.
	- SVM using a linear kernel gets 10% error on spam, and 0.01 error on non-spam
		(acceptable performance)
	- But you want to use logistic regression, because of computational efficiency ,etc
- what to do next? 

- Other common question :
	- Is the algorithm (gradient ascent for logistic regression) converging? 
	- 더 많은 반복을 위해 알고리즘을 훈련하고 훈련하는 것은  거의 해가 되지 않지만 오래 훈련 하면 도움이 될지도 ? 

![[Pasted image 20241112164541.png|350]]

- 최적화를 위해 올바른 함수를 사용하고 있는가?
  학습률은 적절한가?

- BLG를 사용하고 싶지만, SVM이 성능상으로는 BLR(Bayesian logistic regression) 을 능가하므로 각각의 파라미터의 $\theta_{SVM}$ $\theta_{BLR}$ weighted accuracy를 계산하면 
  $$a(\theta) = \max_{\theta}\Sigma_{i}w^{(i)}1(h_{\theta}(x^{i})=y^{i})$$
$$a(\theta_{SVM}) > a(\theta_{BLR})$$
- 최적화 알고리즘의 문제가 있으면 경사하강법은 수렴하지 않음
- 잘못된 비용함수를 이용하면 학습되지 않을 수 있음 
즉, diagnos 해야할 것은
	1. optimizing algorithm이 잘못되서 수렴하지 못하는건지
	2. 비용함수를 잘못 만든 것인지 확인이 필요 

BLR tries to maximize 
$$J(\theta) = \Sigma_{i=1}^{m}\log p(y^{(i)}|x^{(i)},\theta) -\lambda||\theta||^{2}$$
Diagnostic:
$$J(\theta_{SVM}) > J(\theta_{BLR}) $$ 
이 성립 하나? 

optimization algorithm에 문제가 있는 경우 
$$a(\theta_{SVM}) > a(\theta_{BLR})$$
$$J(\theta_{SVM]}) > J(\theta_{BLR})$$maximization 문제가 있는 경우
$$a(\theta_{SVM}) > a(\theta_{BLR})$$
$$J(\theta_{SVM]}) \leq J(\theta_{BLR})$$


