
## Transformer

- AlphaFold3
- GPU & datas & transformer layers

sequence
seq2seq
attention in seq2seq
attention is all you need
multi-self attention
decoding 

self-attention
masked self attentior
masked QKV



### gpt-1

### gpt-2
- Only with text generating , hope it can do a good task at everywhere
- Zero-shot task 

### gpt-3
- one shot, zero shot, few shot

---

- Stanford Alpaca
	- tunnig with gpt chat

---- 
## Clinical LLM

- extract answer from gpt 

- fine tunning <<<<< model size 
---
# tutorial 2
*unsupervised*

## Health care
- 
Score-MRI 

- inverse problem diffusion model can solve it 
- 